{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Lab 11 - Arailym Kaiyrova\n",
    "### Exercise 0: Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, news groups data was loaded from sklearn library, and only for categories 'comp.graphics', 'sci.med'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['comp.graphics', 'sci.med']\n",
    "newsgroups2 = fetch_20newsgroups(categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next part is data cleaning, removing punctuation, stopwords from nltk library, and tokenize data, and store the list of words for each document in list documents.\\\n",
    "'all_words' is a set of all unique words from all documents, which will be neccessary in following tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "all_words = set([])\n",
    "documents = []\n",
    "\n",
    "for i, doc in enumerate(newsgroups2.data):\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    new_words = tokenizer.tokenize(doc.lower())\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    #add the word to the list if its not stopword and not numeric value, and length larger than 1\n",
    "    new_words = [w for w in new_words if (w not in stop_words and w.isalpha() and len(w)>1)]\n",
    "    documents.append(new_words)\n",
    "    \n",
    "    all_words.update(new_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next task is to create bag of words for each documents, and the function 'calculateBOW' creates dictionary of word frequencies for a given document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateBOW(wordset,l_doc):\n",
    "    tf_diz = dict.fromkeys(wordset,0)\n",
    "    for word in l_doc:\n",
    "        tf_diz[word]=l_doc.count(word)\n",
    "    tf_diz['total_count'] = float(len(l_doc))\n",
    "    return tf_diz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And collection of all word frequencies for all documents is stored in a pandas dataframe 'df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heightfield</th>\n",
       "      <th>interleaf</th>\n",
       "      <th>oppose</th>\n",
       "      <th>clut</th>\n",
       "      <th>installworldobjects</th>\n",
       "      <th>freehand</th>\n",
       "      <th>experimentation</th>\n",
       "      <th>unreal</th>\n",
       "      <th>grave</th>\n",
       "      <th>netcom</th>\n",
       "      <th>...</th>\n",
       "      <th>gnv</th>\n",
       "      <th>orders</th>\n",
       "      <th>regional</th>\n",
       "      <th>aga</th>\n",
       "      <th>mirroring</th>\n",
       "      <th>debunking</th>\n",
       "      <th>idealist</th>\n",
       "      <th>moreillo</th>\n",
       "      <th>systematic</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document1173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document1174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document1175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document1176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document1177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1178 rows × 20700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              heightfield  interleaf  oppose  clut  installworldobjects  \\\n",
       "Document0               0          0       0     0                    0   \n",
       "Document1               0          0       0     0                    0   \n",
       "Document2               0          0       0     0                    0   \n",
       "Document3               0          0       0     0                    0   \n",
       "Document4               0          0       0     0                    0   \n",
       "...                   ...        ...     ...   ...                  ...   \n",
       "Document1173            0          0       0     0                    0   \n",
       "Document1174            0          0       0     0                    0   \n",
       "Document1175            0          0       0     0                    0   \n",
       "Document1176            0          0       0     0                    0   \n",
       "Document1177            0          0       0     0                    0   \n",
       "\n",
       "              freehand  experimentation  unreal  grave  netcom  ...  gnv  \\\n",
       "Document0            0                0       0      0       0  ...    0   \n",
       "Document1            0                0       0      0       0  ...    0   \n",
       "Document2            0                0       0      0       0  ...    0   \n",
       "Document3            0                0       0      0       0  ...    0   \n",
       "Document4            0                1       0      0       0  ...    0   \n",
       "...                ...              ...     ...    ...     ...  ...  ...   \n",
       "Document1173         0                0       0      0       0  ...    0   \n",
       "Document1174         0                0       0      0       0  ...    0   \n",
       "Document1175         0                0       0      0       0  ...    0   \n",
       "Document1176         0                0       0      0       0  ...    0   \n",
       "Document1177         0                0       0      0       0  ...    0   \n",
       "\n",
       "              orders  regional  aga  mirroring  debunking  idealist  moreillo  \\\n",
       "Document0          0         0    0          0          0         0         0   \n",
       "Document1          0         0    0          0          0         0         0   \n",
       "Document2          0         0    0          0          0         0         0   \n",
       "Document3          0         0    0          0          0         0         0   \n",
       "Document4          0         0    0          0          0         0         0   \n",
       "...              ...       ...  ...        ...        ...       ...       ...   \n",
       "Document1173       0         0    0          0          0         0         0   \n",
       "Document1174       0         0    0          0          0         0         0   \n",
       "Document1175       0         0    0          0          0         0         0   \n",
       "Document1176       0         0    0          0          0         0         0   \n",
       "Document1177       0         0    0          0          0         0         0   \n",
       "\n",
       "              systematic  total_count  \n",
       "Document0              0        115.0  \n",
       "Document1              0         77.0  \n",
       "Document2              0        287.0  \n",
       "Document3              0        110.0  \n",
       "Document4              0         50.0  \n",
       "...                  ...          ...  \n",
       "Document1173           0        204.0  \n",
       "Document1174           0         59.0  \n",
       "Document1175           0        128.0  \n",
       "Document1176           0         69.0  \n",
       "Document1177           0        133.0  \n",
       "\n",
       "[1178 rows x 20700 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([])\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    wordDict = calculateBOW(all_words,doc)\n",
    "    df = df.append(pd.DataFrame(wordDict, index = ['Document'+str(i)]))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to create term frequencies, or normalized word frequencies, and result is stored in dataframe 'tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pd.DataFrame([], columns = list(all_words))\n",
    "for word in all_words:\n",
    "    tf[word] = df[word]/df['total_count']\n",
    "\n",
    "tf['total_count'] = df['total_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heightfield</th>\n",
       "      <th>interleaf</th>\n",
       "      <th>oppose</th>\n",
       "      <th>clut</th>\n",
       "      <th>installworldobjects</th>\n",
       "      <th>freehand</th>\n",
       "      <th>experimentation</th>\n",
       "      <th>unreal</th>\n",
       "      <th>grave</th>\n",
       "      <th>netcom</th>\n",
       "      <th>...</th>\n",
       "      <th>orders</th>\n",
       "      <th>regional</th>\n",
       "      <th>aga</th>\n",
       "      <th>mirroring</th>\n",
       "      <th>debunking</th>\n",
       "      <th>idealist</th>\n",
       "      <th>moreillo</th>\n",
       "      <th>systematic</th>\n",
       "      <th>total_count</th>\n",
       "      <th>data_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20701 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           heightfield  interleaf  oppose  clut  installworldobjects  \\\n",
       "Document0          0.0        0.0     0.0   0.0                  0.0   \n",
       "Document1          0.0        0.0     0.0   0.0                  0.0   \n",
       "Document2          0.0        0.0     0.0   0.0                  0.0   \n",
       "Document3          0.0        0.0     0.0   0.0                  0.0   \n",
       "Document4          0.0        0.0     0.0   0.0                  0.0   \n",
       "\n",
       "           freehand  experimentation  unreal  grave  netcom  ...  orders  \\\n",
       "Document0       0.0             0.00     0.0    0.0     0.0  ...     0.0   \n",
       "Document1       0.0             0.00     0.0    0.0     0.0  ...     0.0   \n",
       "Document2       0.0             0.00     0.0    0.0     0.0  ...     0.0   \n",
       "Document3       0.0             0.00     0.0    0.0     0.0  ...     0.0   \n",
       "Document4       0.0             0.02     0.0    0.0     0.0  ...     0.0   \n",
       "\n",
       "           regional  aga  mirroring  debunking  idealist  moreillo  \\\n",
       "Document0       0.0  0.0        0.0        0.0       0.0       0.0   \n",
       "Document1       0.0  0.0        0.0        0.0       0.0       0.0   \n",
       "Document2       0.0  0.0        0.0        0.0       0.0       0.0   \n",
       "Document3       0.0  0.0        0.0        0.0       0.0       0.0   \n",
       "Document4       0.0  0.0        0.0        0.0       0.0       0.0   \n",
       "\n",
       "           systematic  total_count  data_target  \n",
       "Document0         0.0        115.0            0  \n",
       "Document1         0.0         77.0            1  \n",
       "Document2         0.0        287.0            0  \n",
       "Document3         0.0        110.0            1  \n",
       "Document4         0.0         50.0            0  \n",
       "\n",
       "[5 rows x 20701 columns]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then idf value was calculated for all words in the dataset according to the formula idf(word) = log(number of documents/number of documents containing the word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heightfield</td>\n",
       "      <td>6.378426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interleaf</td>\n",
       "      <td>5.972961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oppose</td>\n",
       "      <td>6.378426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clut</td>\n",
       "      <td>7.071573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>installworldobjects</td>\n",
       "      <td>7.071573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20694</th>\n",
       "      <td>mirroring</td>\n",
       "      <td>7.071573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20695</th>\n",
       "      <td>debunking</td>\n",
       "      <td>6.378426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20696</th>\n",
       "      <td>idealist</td>\n",
       "      <td>6.378426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20697</th>\n",
       "      <td>moreillo</td>\n",
       "      <td>7.071573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20698</th>\n",
       "      <td>systematic</td>\n",
       "      <td>7.071573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20699 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1\n",
       "0              heightfield  6.378426\n",
       "1                interleaf  5.972961\n",
       "2                   oppose  6.378426\n",
       "3                     clut  7.071573\n",
       "4      installworldobjects  7.071573\n",
       "...                    ...       ...\n",
       "20694            mirroring  7.071573\n",
       "20695            debunking  6.378426\n",
       "20696             idealist  6.378426\n",
       "20697             moreillo  7.071573\n",
       "20698           systematic  7.071573\n",
       "\n",
       "[20699 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "IDF = pd.DataFrame([])\n",
    "N = len(df)\n",
    "for i, word in enumerate(all_words):\n",
    "    idf = np.log(N/df[df[word]!=0][word].count())\n",
    "    IDF = IDF.append(pd.DataFrame([[word,idf]], index = [i]))\n",
    "    \n",
    "IDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that for tf_idf all the term frequencies were multipled by the idf as can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.071573364211532\n"
     ]
    }
   ],
   "source": [
    "tf_idf = pd.DataFrame([], columns = list(all_words))\n",
    "for word in all_words:\n",
    "    idf = IDF[IDF[0]==word].values[0][1]\n",
    "    tf_idf[word] = tf[word]*idf\n",
    "    \n",
    "tf_idf['total_count'] = df['total_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heightfield</th>\n",
       "      <th>interleaf</th>\n",
       "      <th>oppose</th>\n",
       "      <th>clut</th>\n",
       "      <th>installworldobjects</th>\n",
       "      <th>freehand</th>\n",
       "      <th>experimentation</th>\n",
       "      <th>unreal</th>\n",
       "      <th>grave</th>\n",
       "      <th>netcom</th>\n",
       "      <th>...</th>\n",
       "      <th>gnv</th>\n",
       "      <th>orders</th>\n",
       "      <th>regional</th>\n",
       "      <th>aga</th>\n",
       "      <th>mirroring</th>\n",
       "      <th>debunking</th>\n",
       "      <th>idealist</th>\n",
       "      <th>moreillo</th>\n",
       "      <th>systematic</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           heightfield  interleaf  oppose  clut  installworldobjects  \\\n",
       "Document0          0.0        0.0     0.0   0.0                  0.0   \n",
       "Document1          0.0        0.0     0.0   0.0                  0.0   \n",
       "Document2          0.0        0.0     0.0   0.0                  0.0   \n",
       "Document3          0.0        0.0     0.0   0.0                  0.0   \n",
       "Document4          0.0        0.0     0.0   0.0                  0.0   \n",
       "\n",
       "           freehand  experimentation  unreal  grave  netcom  ...  gnv  orders  \\\n",
       "Document0       0.0         0.000000     0.0    0.0     0.0  ...  0.0     0.0   \n",
       "Document1       0.0         0.000000     0.0    0.0     0.0  ...  0.0     0.0   \n",
       "Document2       0.0         0.000000     0.0    0.0     0.0  ...  0.0     0.0   \n",
       "Document3       0.0         0.000000     0.0    0.0     0.0  ...  0.0     0.0   \n",
       "Document4       0.0         0.127569     0.0    0.0     0.0  ...  0.0     0.0   \n",
       "\n",
       "           regional  aga  mirroring  debunking  idealist  moreillo  \\\n",
       "Document0       0.0  0.0        0.0        0.0       0.0       0.0   \n",
       "Document1       0.0  0.0        0.0        0.0       0.0       0.0   \n",
       "Document2       0.0  0.0        0.0        0.0       0.0       0.0   \n",
       "Document3       0.0  0.0        0.0        0.0       0.0       0.0   \n",
       "Document4       0.0  0.0        0.0        0.0       0.0       0.0   \n",
       "\n",
       "           systematic  total_count  \n",
       "Document0         0.0        115.0  \n",
       "Document1         0.0         77.0  \n",
       "Document2         0.0        287.0  \n",
       "Document3         0.0        110.0  \n",
       "Document4         0.0         50.0  \n",
       "\n",
       "[5 rows x 20700 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to divide data into train/test/validation sets according to the ratio 0.8/0.1/0.1.\\\n",
    "Also, to have the equal value of for each category in all datasets, data was separated into two categories and splited into train/test/validation sets.\\\n",
    "Also, for implementation of Naive Bayes, we need two separately consider data for each category, that's why train data for each category was stored separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, frac):\n",
    "    train=df.sample(frac=frac,random_state=200) #random state is a seed value\n",
    "    test=df.drop(train.index)\n",
    "    return train, test\n",
    "\n",
    "def split_data(df):\n",
    "    df['data_target'] = newsgroups2.target\n",
    "\n",
    "    category_1 = df[df['data_target']==1]\n",
    "    category_2 = df[df['data_target']==0]\n",
    "\n",
    "    cat1_train, cat1_test = split_train_test(category_1, 0.8)\n",
    "    cat1_test, cat1_val = split_train_test(cat1_test, 0.5) \n",
    "\n",
    "    cat2_train, cat2_test = split_train_test(category_2, 0.8)\n",
    "    cat2_test, cat2_val = split_train_test(cat2_test, 0.5) \n",
    "\n",
    "    test = pd.concat([cat1_test, cat2_test])\n",
    "    val = pd.concat([cat1_val, cat2_val])\n",
    "    \n",
    "    return cat1_train, cat2_train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Implementing Naive Bayes Classifier for Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Naive Bayes Classifier, we need to calculate contional probablilites of all existing words for each category, which is done by 'calculateTF' method below. \\\n",
    "\n",
    "Condional probabilities were calculated based of regular frequency values, which is stored in table tf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1_train, cat2_train, val, test = split_data(tf)\n",
    "\n",
    "def calculateTF(wordset, dataset):\n",
    "    tf = {}\n",
    "    length = dataset['total_count'].sum()+len(wordset)\n",
    "    for word in wordset:\n",
    "        #Normalized frequency\n",
    "        tf[word]=(dataset[word].sum()+1)/length\n",
    "    return tf\n",
    "\n",
    "p_cat1 = len(cat1_train)/(len(cat1_train)+len(cat2_train))\n",
    "p_cat2 = len(cat2_train)/(len(cat1_train)+len(cat2_train))\n",
    "tf_cat1, tf_cat2 = calculateTF(all_words, cat1_train), calculateTF(all_words, cat2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on condional probabilities in calculated previously, now we can calculate the probability of belonging to specific category of unseen data. So, we calculate its probability of belonging to each category using method 'check_if_cat', and assign the predicted output to the category with higher probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def check_if_cat(p_cat, tf_cat, word_list):\n",
    "    p = p_cat\n",
    "    for word, freq in tf_cat.items():\n",
    "        x = pow(freq, word_list[word])\n",
    "        p*=x\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compare the predicted target values with actual values, and calculate the accuracy, and it can be seen that for validation data accuracy was 62% and for test data it is 69%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of validation set using after bag of words:  0.6271186440677966\n",
      "Accuracy of test set using after bag of words:  0.6949152542372882\n"
     ]
    }
   ],
   "source": [
    "def calculate_acccuracy(p_cat1,p_cat2,tf_cat1,tf_cat2,val):\n",
    "    correct = 0\n",
    "    for i in range(len(val)):\n",
    "        word_list = val.iloc[i].to_dict()\n",
    "        p1 = check_if_cat(p_cat1, tf_cat1, word_list)\n",
    "        p2 = check_if_cat(p_cat2, tf_cat2, word_list)\n",
    "        pred = 1 if p1>p2 else 0\n",
    "        actual = val.iloc[i].values[-1]\n",
    "        if pred==actual:correct+=1   \n",
    "    return correct/len(val)\n",
    "val_acc = calculate_acccuracy(p_cat1,p_cat2,tf_cat1,tf_cat2,val)\n",
    "test_acc = calculate_acccuracy(p_cat1,p_cat2,tf_cat1,tf_cat2,test)\n",
    "\n",
    "print('Accuracy of validation set using after bag of words: ', val_acc)\n",
    "print('Accuracy of test set using after bag of words: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next task is to complete all the previous steps for predicting the output using Naive Bayes Classifies, but instead of using regular frequencies, tf-idf data was used as can bee seen below.\\\n",
    "\\\n",
    "And this approach gives much higher accuracy for both validation and test sets which is above 92%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of validation set using after TF-IDF:  0.923728813559322\n",
      "Accuracy of test set using after TF-IDF:  0.9322033898305084\n"
     ]
    }
   ],
   "source": [
    "cat1_train, cat2_train, val, test = split_data(tf_idf)\n",
    "\n",
    "p_cat1 = len(cat1_train)/(len(cat1_train)+len(cat2_train))\n",
    "p_cat2 = len(cat2_train)/(len(cat1_train)+len(cat2_train))\n",
    "tf_cat1, tf_cat2 = calculateTF(all_words, cat1_train), calculateTF(all_words, cat2_train)\n",
    "\n",
    "val_acc = calculate_acccuracy(p_cat1,p_cat2,tf_cat1,tf_cat2,val)\n",
    "test_acc = calculate_acccuracy(p_cat1,p_cat2,tf_cat1,tf_cat2,test)\n",
    "\n",
    "print('Accuracy of validation set using after TF-IDF: ', val_acc)\n",
    "print('Accuracy of test set using after TF-IDF: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implementing SVM Classifier via Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task we should use SVM for classifying the data. Since we don't need to consider each category separately as for Naive Bayes, training data from each category were combined back into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1_train, cat2_train, val, test = split_data(df)\n",
    "train = pd.concat([cat1_train, cat2_train])\n",
    "X, y = train.iloc[:,range(20699)], train['data_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(pred, test):\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]==test['data_target'].values[i]:\n",
    "            correct+=1\n",
    "    return correct/len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the best hyperparameters, space of different hyperparameter combinations were created, and 10 of the were randomly selected for validation, trained using SVM model built in sklearn library, and the best parameters were selected that gives higher validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C, gamma, kernel type 1 5 poly validation accuracy equals:  0.6271186440677966\n",
      "For C, gamma, kernel type 0.1 0.1 linear validation accuracy equals:  0.9491525423728814\n",
      "For C, gamma, kernel type 0.1 0.1 rbf validation accuracy equals:  0.5\n",
      "For C, gamma, kernel type 100 5 rbf validation accuracy equals:  0.5\n",
      "For C, gamma, kernel type 0.1 10 rbf validation accuracy equals:  0.5\n",
      "For C, gamma, kernel type 100 5 poly validation accuracy equals:  0.6271186440677966\n",
      "For C, gamma, kernel type 1 10 poly validation accuracy equals:  0.6271186440677966\n",
      "For C, gamma, kernel type 1 0.1 linear validation accuracy equals:  0.9491525423728814\n",
      "For C, gamma, kernel type 100 0.1 linear validation accuracy equals:  0.9491525423728814\n",
      "For C, gamma, kernel type 100 10 linear validation accuracy equals:  0.9491525423728814\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "C = [0.1, 1, 100]\n",
    "gammas = [0.1, 5, 10]\n",
    "kernels = ['linear','poly','rbf']\n",
    "space = []\n",
    "for c in C:\n",
    "    for g in gammas:\n",
    "        for k in kernels:\n",
    "            space.append((c,g,k))\n",
    "params = random.sample(range(0, len(space)), 10)\n",
    "\n",
    "best_acc, best_params = -float('inf'), None\n",
    "for p in params:\n",
    "    c,g,k = space[p]\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma=g,kernel=k,C=c))\n",
    "    clf.fit(X, y)\n",
    "    pred = clf.predict(val.iloc[:,range(20699)].values)\n",
    "    accuracy = calculate_accuracy(pred, val)\n",
    "    \n",
    "    print('For C, gamma, kernel type', c, g, k, 'validation accuracy equals: ', accuracy)\n",
    "    if accuracy>best_acc:\n",
    "        best_acc, best_params = accuracy, space[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it can be seen that for C = 0.1, gamma = 0.1, and 'linear' kernel type, model gives higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 0.1, 'linear')"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below test accuracy was calculated for model with selected best hyperparameters, and it gives high accuracy, which is above 95 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With selected best parameters C, gamma, kernel type 100 10 linear test accuracy equals:  0.9576271186440678\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma=best_params[1],kernel=best_params[2],C=best_params[0]))\n",
    "clf.fit(X, y)\n",
    "pred = clf.predict(test.iloc[:,range(20699)].values)\n",
    "accuracy = calculate_accuracy(pred, test)\n",
    "    \n",
    "print('With selected best parameters C, gamma, kernel type', c, g, k, 'test accuracy equals: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
